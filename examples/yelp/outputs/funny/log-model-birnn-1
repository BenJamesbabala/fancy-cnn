Model trained at 2016-02-18 04:37:53
Accuracy obtained: 0.832889267825
Error obtained: 0.167110732175
================================================================================
Model in json:
================================================================================
{"loss": {"prediction": "binary_crossentropy"}, "optimizer": {"beta_1": 0.8999999761581421, "epsilon": 1e-08, "beta_2": 0.9990000128746033, "lr": 0.0010000000474974513, "name": "Adam"}, "name": "Graph", "output_config": [{"inputs": [], "name": "prediction", "concat_axis": -1, "merge_mode": "concat", "dot_axes": -1, "input": "probability"}], "input_config": [{"dtype": "int", "name": "input", "input_shape": [300]}], "node_config": [{"inputs": [], "name": "wvs", "concat_axis": -1, "merge_mode": "concat", "dot_axes": -1, "create_output": false, "input": "input"}, {"inputs": [], "name": "gru_forwards", "concat_axis": -1, "merge_mode": "concat", "dot_axes": -1, "create_output": false, "input": "wvs"}, {"inputs": [], "name": "gru_backwards", "concat_axis": -1, "merge_mode": "concat", "dot_axes": -1, "create_output": false, "input": "wvs"}, {"inputs": ["gru_forwards", "gru_backwards"], "name": "gru_dropout", "concat_axis": -1, "merge_mode": "concat", "dot_axes": -1, "create_output": false, "input": null}, {"inputs": [], "name": "probability", "concat_axis": -1, "merge_mode": "concat", "dot_axes": -1, "create_output": false, "input": "gru_dropout"}], "output_order": ["prediction"], "input_order": ["input"], "nodes": {"wvs": {"W_constraint": null, "name": "Embedding", "custom_name": "embedding", "output_dim": 300, "trainable": false, "input_shape": [120002], "cache_enabled": true, "init": "uniform", "input_dim": 120002, "mask_zero": false, "W_regularizer": null, "activity_regularizer": null, "input_length": null}, "gru_backwards": {"name": "GRU", "custom_name": "gru", "inner_activation": "hard_sigmoid", "go_backwards": true, "output_dim": 128, "trainable": true, "stateful": false, "cache_enabled": true, "init": "uniform", "inner_init": "orthogonal", "input_dim": 300, "return_sequences": false, "activation": "sigmoid", "input_length": null}, "gru_dropout": {"cache_enabled": true, "trainable": true, "name": "Dropout", "custom_name": "dropout", "p": 0.5}, "gru_forwards": {"name": "GRU", "custom_name": "gru", "inner_activation": "hard_sigmoid", "go_backwards": false, "output_dim": 128, "trainable": true, "stateful": false, "cache_enabled": true, "init": "uniform", "inner_init": "orthogonal", "input_dim": 300, "return_sequences": false, "activation": "sigmoid", "input_length": null}, "probability": {"W_constraint": null, "b_constraint": null, "name": "Dense", "custom_name": "dense", "activity_regularizer": null, "trainable": true, "cache_enabled": true, "init": "uniform", "activation": "sigmoid", "input_dim": null, "b_regularizer": null, "W_regularizer": null, "output_dim": 1}}}
================================================================================
Model summary:
================================================================================
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #             
--------------------------------------------------------------------------------
Layer (input)                 (None, 300)                   0                   
Embedding (wvs)               (None, None, 300)             36000600            
GRU (gru_forwards)            (None, 128)                   164736              
GRU (gru_backwards)           (None, 128)                   164736              
Dropout (gru_dropout)         (None, 256)                   0                   
Dense (probability)           (None, 1)                     257                 
Dense (prediction)            (None, 1)                     257                 
--------------------------------------------------------------------------------
Total params: 36330329
--------------------------------------------------------------------------------
================================================================================
Training history:
================================================================================
Epoch 1: loss: 0.499166, val_loss: 0.429733
Epoch 2: loss: 0.428383, val_loss: 0.420047
Epoch 3: loss: 0.411297, val_loss: 0.404272
Epoch 4: loss: 0.400868, val_loss: 0.402312
Epoch 5: loss: 0.392838, val_loss: 0.398004
Epoch 6: loss: 0.387125, val_loss: 0.389312
Epoch 7: loss: 0.381396, val_loss: 0.388893
Epoch 8: loss: 0.375344, val_loss: 0.387183
Epoch 9: loss: 0.369441, val_loss: 0.393543
Epoch 10: loss: 0.365079, val_loss: 0.382359
Epoch 11: loss: 0.358183, val_loss: 0.381383
Epoch 12: loss: 0.352438, val_loss: 0.380137
Epoch 13: loss: 0.348296, val_loss: 0.378941
Epoch 14: loss: 0.340272, val_loss: 0.394562
Epoch 15: loss: 0.335226, val_loss: 0.380415
Epoch 16: loss: 0.330169, val_loss: 0.392902
Epoch 17: loss: 0.326606, val_loss: 0.387091
Epoch 18: loss: 0.318449, val_loss: 0.381300
Epoch 19: loss: 0.313084, val_loss: 0.390451
================================================================================
Code file:
================================================================================
import cPickle as pickle

import numpy as np
from keras.layers.recurrent import GRU
from keras.models import Sequential, Graph
from keras.layers.core import Dense, Activation, Dropout
from keras.callbacks import EarlyStopping, ModelCheckpoint

import sys
sys.path.append("..")
from nn import train_neural
from cnn.layers.embeddings import *

MODEL_FILE = './yelp-model-birnn-1'
LOG_FILE = './log-model-birnn-1'

# Read back data
train_reviews = np.load("../Yelp_funny_train_fulltext_glove_300_X.npy")
train_labels = np.load("../Yelp_funny_train_fulltext_glove_300_y.npy")
test_reviews = np.load("../Yelp_funny_test_fulltext_glove_300_X.npy")
test_labels = np.load("../Yelp_funny_test_fulltext_glove_300_y.npy")

WV_FILE_GLOBAL = '../data/wv/glove.42B.300d.120000-glovebox.pkl'

gb_global = pickle.load(open(WV_FILE_GLOBAL, 'rb'))

wv_size = gb_global.W.shape[1]

model = Graph()
model.add_input('input', (len(train_reviews[0]), ), dtype='int')
model.add_node(make_embedding(vocab_size=gb_global.W.shape[0], init=gb_global.W, wv_size=wv_size,
                         fixed=True, constraint=None), name='wvs', input='input')
model.add_node(GRU(128, init='uniform'), name='gru_forwards', input='wvs')
model.add_node(GRU(128, go_backwards=True, init='uniform'), name='gru_backwards', input='wvs')
model.add_node(Dropout(0.5), name='gru_dropout', inputs=['gru_forwards', 'gru_backwards'])
model.add_node(Dense(1, init='uniform', activation='sigmoid'), name='probability', input='gru_dropout')
model.add_output(name='prediction', input='probability')

model.compile(loss={'prediction': 'binary_crossentropy'}, optimizer='adam')

fit_params = {
    "data": {
        'input': train_reviews,
        'prediction': train_labels
    },
    "batch_size": 32,
    "nb_epoch": 50,
    "verbose": True,
    "validation_split": 0.1,
    "callbacks": [EarlyStopping(verbose=True, patience=5, monitor='val_loss'),
                  ModelCheckpoint(MODEL_FILE, monitor='val_loss', verbose=True, save_best_only=True)]
}

history = train_neural.train_graph(model, fit_params)
acc = train_neural.test_graph(model, {'input': test_reviews}, 'prediction', test_labels, MODEL_FILE)
train_neural.write_log(model, history, __file__, acc, LOG_FILE)
